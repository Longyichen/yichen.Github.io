<template><h1 id="reading-report" tabindex="-1"><a class="header-anchor" href="#reading-report" aria-hidden="true">#</a> Reading Report</h1>
<blockquote>
<p>前述为文章研究内容的总结归纳，个人思考请参照最后一部分[[#My Thinking]]</p>
</blockquote>
<h2 id="metadata" tabindex="-1"><a class="header-anchor" href="#metadata" aria-hidden="true">#</a> Metadata</h2>
<ul>
<li>
<p>Item Type: [[Article]]</p>
</li>
<li>
<p>Authors: [[Lu Cao]], [[Dandan Huang]], [[Yue Zhang]], [[Xiaowei Jiang]], [[Yanan Chen]]</p>
</li>
<li>
<p>Date: [[2021-05-18]]</p>
</li>
<li>
<p>Date Added: [[2022-09-29]]</p>
</li>
<li>
<p>URL: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17493" target="_blank" rel="noopener noreferrer">https://ojs.aaai.org/index.php/AAAI/article/view/17493</a></p>
</li>
<li>
<p>DOI: <a href="https://doi.org/10.1609/aaai.v35i14.17493" target="_blank" rel="noopener noreferrer">10.1609/aaai.v35i14.17493</a></p>
</li>
<li>
<p>Cite key: caoBrainDecodingUsing2021</p>
</li>
<li>
<p>Topics: [[计算神经科学]]</p>
</li>
</ul>
<hr>
<h2 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract" aria-hidden="true">#</a> Abstract</h2>
<p>大脑的激活可以反映出由自然界的词语和概念所引起的语义信息。反应大脑激活的表征语义有很多，比如ECoG、fMRI、MEG和EEG技术等等。目前使用这些技术研究神经激活模式，结合语言模型进行大脑思考的解码工作越来越多。在神经生理反应解码语义的工作中，每种技术都有其自身的优势和局限性，那种技术作为最优的生理特征载体还没有定论。这篇文章研究了基于血流动力学的功能性近红外光谱（fNIRS）在语义解码任务中的应用，并将其与fMRI进行经验性比较，总结里fNIRS的优劣性。他们的贡献有：</p>
<ol>
<li>与fMRI扫描一样，fNIRS记录的激活模式为分辨概念编码了丰富的信息，但在<mark>解码细粒度语义线索的可能性上显示出局限</mark>性</li>
<li>fNIRS解码在不同的脑区、语义类别甚至是受试者之间显示出<mark>稳健性</mark></li>
<li>与单通道模式相比，fNIRS<mark>在多通道模式的基础上解码的准确性更高</mark></li>
<li>发布了fNIRS数据集</li>
</ol>
<hr>
<h2 id="problem-to-solve-and-paper-hypothesis" tabindex="-1"><a class="header-anchor" href="#problem-to-solve-and-paper-hypothesis" aria-hidden="true">#</a> Problem to Solve and Paper Hypothesis</h2>
<p>本文关注与大脑解码，即根据明确的语言表征和深度学习算法解释隐性的大脑活动。人工智能模型所捕获的智能语言理解行为在多大程度上与人类阅读生理学相一致,这一直都是目前研究的热点。在之前的研究中，人们已经证明<mark>同一个词的大脑神经基础和语料库分布属性是高度相关的</mark>（Mitchell等人，2008）</p>
<p>在大脑解码的工作中，解码所用的数据一直都是重要的前提和制约。现有的方法如皮质电图（ECoG）、脑电图（EEG）、功能磁共振成像（fMRI）和脑磁图（MEG）每种方法都有其相对优势和劣势。关于功能性近红外光谱（fNIRS）在解码方面的研究则比较少。如图所示，fNIRS记录需要参与者在头皮表面戴上一个帽子，上面嵌入了近红外光的发射器和探测器。发射器发射光线，而探测器接收穿过组织的光线。探测器-发射器对形成一个通道，在这个通道内可以记录血液动力学反应，并且可以根据血红蛋白对近红外光的吸收和散射来检测活跃的大脑皮层区域。最后，检测到的新兴fNIRS信号主要来自位于小血管中的氧合血红蛋白和脱氧血红蛋白。因此，与其他神经成像工具相比，fNIRS显示出无创性、高时间分辨率、低实验成本、全兼容性、多种生物标志物和高运动耐受性等优势。
![[Pasted image 20220930094332.png]]</p>
<p>本文假设fNIRS代表的神经生理反应和大脑思考时理解的语义有所关联，并且可以借由<mark>神经影像学实验建立概念和神经激活模式之间的映射</mark>。如下公式所示，给定的大脑图像意味着单词或文本片段的心理内容，大脑解码的任务是预测唤起这种神经模式的刺激单词，其中 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">i</span><span class="mord cjk_fallback">，</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> 别是<mark>大脑激活图像和刺激单词</mark>。目标是学习映射函数 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span>，在大多数情况下，它是一个线性模型:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span></p>
<p>Zinszer等人（2017）首次尝试将fNIRS信号与具体词汇的表述联系起来，但存在数据集较小。文本作者首先用Zinszer等人的材料进行了小规模的初步测试，旨在评估fNIRS操作的可行性、持续时间、通道配置、电极设置、感兴趣的大脑区域和解码策略。之后他们用试验研究决定的超参数进行全面的数据收集和解码实验，验证了使用fNIRs在自然语言模型是的映射解码能力，并发布了涵盖了10个语义类别的50个对象的数据集。</p>
<hr>
<h2 id="solution" tabindex="-1"><a class="header-anchor" href="#solution" aria-hidden="true">#</a> Solution</h2>
<p>如前文所述，fNIRS在多个位置大脑单词的血流动力反应。根据假设，大脑思考的血流动力学特征与人工智能在NLU中学习到的语义相关。本文使用GloVe Word Embedding - 因为其产生每个词的维度向量表示，被广泛应用于大脑解码的相关任务中，并且具有较好的性能。作者认为使用其他的语义表征不会对解码任务产生明显对提升。
作者定义解码模型如下， <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span></span></span></span></span></span></span></span> 代表响应第 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 个刺激的 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">im</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">na</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span> HbO（作者收集的大脑活动数据），<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 代表GloVe词向量。对于每个受试者和刺激触发的HbO变化，作者使用脊回归来学习一个线性图 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord cjk_fallback">：</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>，使函数最小化，其中<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>是一个正则化超参数。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>线性回归模型的训练和测试是通过leave-two-out和leave-on-out交叉验证进行的。leave-two-out的方法中，模型使用<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.175em;vertical-align:-0.3337em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen"><span class="mopen">(</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3337em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>刺激物反复训练，并使用遗漏的两个刺激物进行测试。在leave-on-out中，模型使用<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.175em;vertical-align:-0.3337em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen"><span class="mopen">(</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3337em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>刺激物进行训练，并使用遗漏的一个刺激物进行测试。
作者探索了两种解码策略，即单通道解码（SCD）和多通道解码（MCD），前者对每个通道单独解码，并给出一个平均结果。后者则是将多个通道的信号作为一个整体一次性考虑</p>
<h3 id="baseline-evaluate-matrix" tabindex="-1"><a class="header-anchor" href="#baseline-evaluate-matrix" aria-hidden="true">#</a> Baseline &amp; Evaluate Matrix</h3>
<p>为了证明从大脑活动到词向量的映射是稳健的，作者采用随机扰乱对（RSP）作为我们的基线之一。在这种情况下，刺激和相应的fNIRS信号被随机地洗掉。模型性能与RSP基线的比较是为了确定该映射是可靠的，而不是噪音的结果。
作者使用fMRI概念解码任务（Mitchell等人，2008）作为比较基线之一，fNIRS和fMRI测量的血液动力学反应在空间和时间上是相关的，因此，研究fNIRS和fMRI在大脑解码能力上的差异是有意义的。
leave-two-out的解码性能由匹配分数（MS）指标来评估，leave-on-out则由平均平方误差（MSE）指标来评估。
两个测试刺激<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">（</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord">1</span><span class="mord cjk_fallback">，</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord">2</span><span class="mord cjk_fallback">）</span></span></span></span>和 grand truth 词向量<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">（</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">1</span><span class="mord cjk_fallback">，</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mord cjk_fallback">）</span></span></span></span>，该模型预测<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord">1</span></span></span></span>的词向量<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mord">1</span></span></span></span>和<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord">2</span></span></span></span>的<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mord">2</span></span></span></span>。然后它决定哪一个是更好的匹配：<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord cjk_fallback">（</span><span class="mord mathnormal">p</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mord cjk_fallback">）</span></span></span></span>或<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord cjk_fallback">（</span><span class="mord mathnormal">p</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">1</span></span></span></span>）。匹配得分被分配为</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">MS</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">cos</span><span class="mord mathnormal">in</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">cos</span><span class="mord mathnormal">in</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mclose">)</span></span></span></span></span></p>
<hr>
<h2 id="experiment" tabindex="-1"><a class="header-anchor" href="#experiment" aria-hidden="true">#</a> Experiment</h2>
<h3 id="pilot-study" tabindex="-1"><a class="header-anchor" href="#pilot-study" aria-hidden="true">#</a> Pilot Study</h3>
<p>作者首先进行试点研究，以评估可行性并调整实验设置和超参数。主要过程为，一连串的概念被呈现给受试者，记录他们的皮质活动在每个瞬间的处理过程。每个刺激物被呈现12次，每次呈现的物品顺序随机排列。视觉呈现持续3秒，音频在开始时立即呈现，随后是10秒的休息时间。在休息期间，参与者被要求在屏幕中央显示的X上打钩。与者的任务是被动地观看和聆听，只需专注于每个刺激物，并在其<mark>呈现时自由思考物体的属性</mark>。在整个暴露过程中，参与者的血氧水平由NIRx NIRScout fNIRS系统测量探头被安排在三个阵列中：<mark>后部有26个通道，大约覆盖枕叶；左颞叶有10个通道；右颞叶有10个通道</mark>。</p>
<p>从解码策略的角度上，作者比较了两种分析方法：单通道解码（SCD）和多通道解码（MCD）。作者测试统计量为SCD、MCD和RSP基线之间的差异，通过置换实验验证1000次，显著性水平设定为0.05。如表2所示，SCD的性能在两个指标下都没有明显优于RSP（MS：p&gt;0.16，MSE：p&gt;0.92），而MCD在MS指标下明显优于RSP（p&lt;0.03）。这表明，对于fNIRS来说，与单通道方案相比，多通道解码是一个更好的选择，因此之后的分析都是基于多通道解码。</p>
<p>![[Pasted image 20221001234359.png]]
从词嵌入尺寸的角度上来说，作者观测到GloVE的嵌入尺寸为50、100、200和300时都有比较稳定的匹配分数，低维度的GloVE词嵌入对fNIRS模式的解码性能稍好。这一现象可能表明，从fNIRS人类神经影像中解码高维嵌入所编码的精细语义信息的可能性存在限制。因此，我们在下面的分析中把词向量的维度定为50。
![[Pasted image 20221001234733.png]]
从测试时间而言，对6.5s到7.5s之间的信号进行解码会得到最好的匹配分数，而随着时间的推移，性能会下降。这与我们的直觉是一致的，即刺激后生理信号的强度逐渐减弱。因此，我们在下面的实验中把解码时间窗口定为6.5-7.5秒。</p>
<p>从大脑区域的角度而言，作者全面收集大脑左、右和枕部的fNIRS数据。无效假设为其解码性能在脑区之间没有差异。作者将显著性水平设定为0.05，并通过置换检验来检验显著性。如表3所示，两个指标下的P值都高于显著性水平，没有拒绝无效假设。这表明与fMRI相比，fNIRS在不同区域的表现没有明显的差异。
![[Pasted image 20221001235106.png]]</p>
<h3 id="full-scale-experiment" tabindex="-1"><a class="header-anchor" href="#full-scale-experiment" aria-hidden="true">#</a> Full Scale Experiment</h3>
<p>所有的受试者都为right-handed。作者从10个更广泛的语义类别中采用了50个经常使用的概念，每个类别有5个典范，每个刺激物随机呈现7次。为了避免疲劳，我们将实验分为两个时段，每个时段呈现25个词，之间有十分钟的休息时间。fNIRS探针被安排覆盖左颞叶、顶叶和前额叶，共有22个通道。由于各区域的表现在fNIRS记录下没有明显的差异，我们将fNIRS探针从试点研究的46个通道减少到22个通道，主要集中在左半球。与试验研究相比，这项任务的探测器-发射器对较少，因此采样率较高。</p>
<hr>
<h2 id="result-and-analysis" tabindex="-1"><a class="header-anchor" href="#result-and-analysis" aria-hidden="true">#</a> Result and Analysis</h2>
<p>在跨语义类别分类方面，作者通过从训练集中排除同一类别的所有单词来预测新类别的单词，并通过置换实验验证。结果显示，类内解码（p&gt;0.09）和类外解码（p&gt;0.21）的匹配得分并不明显低于类间解码。fNIRS表现出强大的区分能力，即使在离开类别的条件下，解码的概念仍然是可以区分的，fNIRS也有可能被扩展到不同的语义空间。
![[Pasted image 20221001235602.png]]
在跨主题方面，作者将受试者分为训练组和测试组，依次对1名受试者进行训练，对其余6名受试者进行测试，并将6名受试者的表现取平均值作为本次迭代的总体表现。然后，我们用2名受试者进行训练，依次用其余5名受试者进行测试。实验重复进行，直到最后一组用6名受试者进行训练，用剩余的受试者进行测试。作者对所有可能的组合进行迭代，结果显示，MSE的下降，性能更强。
![[Pasted image 20221001235714.png]]
刺激物的影响方面，作者担心随着实验刺激的扩大，实验时间变得更长，因此受试者可能会或多或少地分心，影响信号质量。作者比较了试验研究和全面实验的解码性能，前者包括8个概念，持续25分钟，后者包括50个概念，持续50分钟，结果显示，随着实验时间的延长和概念的增加，解码性能并没有明显的下降（P&gt;0.12）。这意味着，在一定程度上增加刺激物的数量是可以接受的。</p>
<p>![[Pasted image 20220930110200.png]]
作者还仔细分析了fNIRS和fNIRS的新能差距。fMRI解码比fNIRS解码<mark>有更高的准确性</mark>，在类别间、离开一个类别和类别内方面。一个可能的原因是，fMRI扫描<mark>覆盖了整个大脑（侧面和深度），可以是50,000到200,000维</mark>，而fNIRS仅限于大脑表面，通常少于10,000维。这显示了<mark>fNIRS在穿透深度方面的局限性</mark>。然而，结果也表明，fNIRS具有强大的<mark>跨类别解码能力，因为三种条件下的匹配得分没有明显的变化</mark>。相反，对于fMRI信号，从类别间解码到离开一个类别的解码，准确率急剧下降，而类别内解码的下降幅度更大。
图4总结了跨主体解码的性能。评价指标是均方误差。正如前面所讨论的，fNIRS信号可以保留不同主体之间的共性。相反，当涉及更多的受试者时，fMRI的均方误差会增加。我们的结论是，fMRI比fNIRS具有更高的特定主体和特定类别的记录准确性，而且fNIRS在不同条件下具有更高的稳健性。这可能为fMRI和fNIRS技术的结合提供了新的可能性。<mark>这两种方法可以相互补充，并允许更复杂的研究范式</mark></p>
<hr>
<h2 id="my-thinking" tabindex="-1"><a class="header-anchor" href="#my-thinking" aria-hidden="true">#</a> My Thinking</h2>
<p>这篇文章主要研究使用fNIRS进行大脑解码的可行性和性能。大脑解码是将大脑思考时的刺激物反应同刺激语义进行联系和映射的过程，从而达到传统意义上的“解读思考”的目的。需要达成这个过程有几个前提条件：</p>
<ol>
<li>大脑的刺激反应能够代表思考的内容</li>
<li>思考可以用某些语义工具表示</li>
<li>实验用检测脑刺激的工具和手段能够比较全面的反映脑刺激的过程和内容</li>
<li>脑刺激的某些特征和人类描述的语义具有一定的映射关系</li>
</ol>
<p>目前的研究中，科学家已经证明了1，4，关于2，目前人类普遍使用自然语言表达思考，而在大脑解码中计算机对于人类语言的建模 - Word Embedding 则被广泛使用-因为其代表了词汇在高纬语言空间中的一种表示。它们被证明在广泛的自然语言任务中是非常有效的，但是在大脑解码中，词嵌入是否能表征思考，不同的词嵌入表征思考的方式会不会不同，用同一个语系、甚至个人训练出来的或者使用很大语料的、共性的思考训练得出的词嵌入会不会有不同的效果，哪种效果更好等等，在目前的研究中并没有广泛的实验，是值得研究的开放性问题。甚至于，个人认为，由于大脑活动的巨大差异，和词嵌入的连续性、精确性 - 使用通用的，广泛训练的词嵌入不一定最终能够达成较为精确的，词级别的精确映射。同时，由于词嵌入是独立的，词汇级别的嵌入，而思维可能是连续的、句式甚至是篇章级别的，如何使用词嵌入解决句级的思维解码，或者更换其他表征语义的工具也都是值得研究的问题。在这方向我有一点思考：语义可能是更高层级的神经网络特征，不一定是具体的词或者短语，可能用一类聚类表示。</p>
<p>文本研究的重点是3。目前学术界还在广泛地研究各种解码方式在brain decoding任务上的可行性，之前阅读和分析的一篇论文[[REPORT OF  IMPROVING BRAIN DECODING METHODS AND EVALUATION]] 使用 fMRI 作为脑神经活动表征进行语义的预测。而文本假设fNIRS代表的神经生理反应和大脑思考时理解的语义有所关联，可以借由<mark>神经影像学实验建立概念和神经激活模式之间的映射</mark>。本文将大脑解码问题建模为一个经典的自然语言理解的映射问题。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span></p>
<p>i，v分别是大脑激活图像和刺激单词。这个任务范式给了我众多想象空间，例如是否可以借鉴自然语言的方法将深度神经网络运用于大脑思考的解码，或者通过训练仿生大脑结构的神经网络，以研究脑结构的形成和模拟等等。作者使用在10个语义类别的50个经常使用的概念中进行了大规模的fNIRS研究，并且使用fNIRS同更为主流的fMRI进行对比。总结而言，本文的贡献可以分为以下几点：</p>
<ol>
<li>本文进行了大规模的fNIRS实验并且公开了实验数据集供下载</li>
<li>本文证明了fNIRS可以将丰富的语言信息编码到神经信号中，fNIRS在任务中有特点
<ol>
<li>解码细粒度语义信息的可能性上显示出局限性</li>
<li>fNIRS解码在不同的脑区、语义类别甚至是受试者之间显示出鲁棒性</li>
</ol>
</li>
</ol>
<p>基于本文，除上文点探讨外，我觉得还有这些点值得研究：</p>
<ol>
<li>Word Embedding等人工智能建模的语义特征到底有没有和大脑建模的语义特征相关，目前大脑建模等语义特征体现出个性化、模态间关联复杂等特点，而目前等语义特征主要基于共识。是否能够提出一个特别等语义表征模型用于decoding中？大脑的语义表征模型是否在某些方面会比自然语言的表征模型具有优势，例如能够更好的进行感情分类等预测。</li>
<li>fNIRS的数据具有一定的共性，相对于fMIRS在个性化的识别上更强，是否说明共性的信息特征较为浅层，而个性的信息特征则存储于更深的大脑结构中。能否不同人对于同一个事物的共性认知抽离出来。一方面这个方法对于自然语言建模的语义特征具有更高的相似性。另一方面，我们可以将预训练模型的思想引入大脑的通用语义模型建立之中 - 即： 能否将建模共识和建模个体知识分开，先建模通用共识，之后在个人知识上进行微调，最终获得具有个性化的解码模型。考虑到数据的质量，可获取性，统一性，虽然目前技术还不成熟，但是在未来这肯定是可行的</li>
<li>作者发布的fNIRS数据集涵盖了10个语义类别的50个对象。其中的语义类别和对象在深度学习领域还是太少了。一方面我们可以获得更多的数据，构建更大更强的数据集。另一方面，当我们迁移深度学习任务时，我们应该使用对数据需求少的模型和方法，比如fewshot、小样本，或者使用数据增强、数据融合等方法来辅助训练。</li>
<li>作者使用比较传统的机器学习方法 - 脊回归来构建模型。是否能够更复杂的预训练模型学习，借助深度学习的小样本分析方式，使用其他数据来提升预测性能。或许考虑auto encoder和transformer之类的生成式模型会有比较好的效果？由于生成式模型对信息的建模更为深入，更符合人类说话的思考方式，是不是具有更强的性能。犹豫思考同样具有时间特征，因此使用时序的端到端模型是否会更适合</li>
<li>EEG、fMRI、fNRS等方法拥有不同的衡量方式。比如EEG测量脑电，fMRI关注血液动力学，这其中也涉及到生物电和神经信号哪个更能代表大脑的活动等值得研究的问题。fNIRS受限于本身的性能，只能覆盖大脑表面，具有局限性，在未来的更细粒度解码上存在上限。然而，当我们研究一些存储于大脑表面的信息，拥有较低获取难度的fNIRS就更具有优势。需要更具需求选择合适的方法。</li>
<li>文章使用MS和MSE来进行预测结果的衡量。这基本上是借鉴了自然语言研究， 评价指标整体来看还是比较简单的。由于语义本身的特殊性，能不能进一步的衡量语义匹配性。或者提出一个衡量语义匹配的方法</li>
<li>从结果来看，模型的准确率还是比较低的。说明训练的方法没有很好的拟合训练数据集，这可能是模型或者数学的缺乏造成的。但是总体来说，fNIRS数据比较简单，关注的信息比较低维，或许还是比较现在的比较简单的解码任务</li>
<li>由于数据不足问题，和各种信息的互补性，能不能利用不同的脑信息，汇总比较通用的模型。</li>
</ol>
<hr>
<h2 id="reference" tabindex="-1"><a class="header-anchor" href="#reference" aria-hidden="true">#</a> Reference</h2>
<p>Brain Decoding Using fNIRS
Data and Code: https://www.dropbox.com/s/b7bca82ug1112km/aaai2021_cr.rar?dl=0
https://github.com/caolusg/decoding_fnirs</p>
</template>
